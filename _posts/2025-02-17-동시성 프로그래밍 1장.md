---
layout: post
title: 동시성과 병렬성
author: nowpassion
date: 2025-02-17
tags: "동시성_프로그래밍"
---
## 프로세스
* 프로세스란 계산을 실행하는 주체로 크게 다음 네 가지 상태를 변경하면서 계산을 진행한다.
  1. 실행 전 상태 : 계산을 실행사기 전의 상태
  1. 실행 상태 : 계산을 실행하고 있는 상태
  1. 대기 상태 : 계산을 일시적으로 정지한 상태. 실행 상태로 전이할 수 있다.
     * 데이터를 도착하기를 기다리는 경우
     * 계산 리소스 확보를 기다리는 상태 (커널의 Mutex)
     * 자발적으로 대기 상태로 전입하는 경우 (타이머)
  1. 종료 상태 : 계산을 종료한 상태

## 동시성
  * 동시성은 2개 이상의 프로세스가 동시에 계산을 진행하는 상태
  * 싱글태스트 OS vs 멀티태스크 OS
  * 프로세스와 스레드
    * 프로세스는 커널에서 본 프로세스를 의미
    * 스레드는 OS 프로세스 안에 포함된 프로세스로 분류
  * OS 프로세스는 OS가 독립된 가상 메모리 공간을 할당
  * 스레드는 OS 프로세스의 가상 메모리 공간과 시스템 자원을 공유한다.
  * [싱글 스레드 프로그램 vs 멀티 스레드 프로그램](https://homepages.math.uic.edu/~jan/mcs572f16/mcs572notes/lec10.html)
  ![process_memory](/assets/images/process_memory.png)

## 병렬성
* 같은 시각에 여러 프로세스가 동시에 계산을 실행하는 상태 (프로세스 관점의 병렬성)
* 컴퓨터 아키텍처 (하드웨어) 관점의 병렬성
  * 태스크 병렬성 : 여러 태스크가 동시에 여러 CPU를 통해 수행되는 것
  * 데이터 병렬성 : 데이터를 여러 개로 나눠서 병렬로 처리하는 방법
    * 무엇이 빠를 것인가?
      * $v_1 = [1,2,3,4] v_2 = [5,6,7,8]$
      * 네 개의 요소를 가지고 있는 벡터 둘을 하나의 연산자로 계산하는 것
      * 네 개의 요소를 가지고 있는 벡터 둘을 하나의 4개의 연산자로 계산하는 것
    * Intel CPU의 AVX 명령 (SIMD(Single instruction, multiple data
    )의 확장판)
    * GPGPU
    * 응답 속도와 처리량
      * 계산 속도는 응답 속도와 처리량이라는 두 가지 척도
      * 응답 속도는 소비하는 CPU 클럭 수나 소비하는 CPU 인스트럭션 수로 나타낼 수 있음.
        * $응답속도 = \frac{소비 CPU 클럭 수}{CPU 작동 클록 주파수}[s]$
        * $응답속도 = \frac{소비 CPU 인스트럭트 수 \times CPI}{CPU 작동 클록 주파수}[s]$
        * CPI (Cycles Per Instruction)
      * 처리량이란 단위 시간당 실행 가능한 계산량
        * MIPS(Million Instructions Per Second), FLOPS(Floating Point Operations Per Second)
        * FLOPS(Floating Point Operations Per Second)는 CPU의 부동소수점 연산 속도를 나타내는 단위
    * 암달의 법칙
      * 병렬화를 통한 응답 속도 향상 정도를 결정하는 요소
        * 병렬화 가능한 처리 부분과 병렬화 불가능한 처리부분의 비율
        * 병렬화를 위한 오버헤드 수준
      * 암달의 법칙
        * $\frac{1}{H+(1-P)+\frac{P}{N}}$
        * P는전체 프로그램 중에서 병렬화 가능한 처리가 차지하는 비율 (0 ~ 1 사이)
        * N은 병렬화 수
        * H는 병렬화 오버헤드의 응답 속도와 순차 실행했을 때의 응답 속도의 비율 
        * P가 1에 가깝고, N이 크며, H가 적을 수록 (즉 오버헤드가 작을 수록) 응답 속도 향상률이 올라간다. 
  * 인스트럭션 레벨 병렬성
    * CPU 명령어 레벨에서 병렬화를 수행하는 방법
    * 루프 전개(Loop Unrolling)
      * 루프 전개를 수행함으로써 조건문 수행 빈도를 낮춰 인스트럭션 레벨 병렬성을 높힐 수 있다.
      * pipelining 효율성을 높힐 수 있다(?)
    * 데이터 프리레치(Data prefetch)
      * 나중에 메모리에 있는 데이터를 이용해 계산을 수행할 것을 미리 알고 있을 경우 사전에 데이터를 읽어두는 방법
      * 이유 -> 덧셈이나 뺄셈 같은 명령어 비해 메모리 읽기 명령은 응답속도가 느리기 때문임.
    * pipeline
      * CPI (Clock cycle Per Instruction)
        * 8 클록으로 4개의 명령을 파이프라인을 통해 수행할 경우 CPI는 2이다. ($\frac{8}{4}=2$)
        * 4개의 명령을 직렬로 수행할 경우 CPI는 2이다. ($\frac{20}{4}=5$)
        * 그러므로 위의 경우 파이프라인을 통해 얻을 수 있는 이득은 2.5 배이다. ($\frac{5}{2}=2.5$)
      * out-of-order 수행 
      * pipeline hazard
        * 데이터 의존 관계등의 원인으로 인스트럭션 레벨에서 병렬 실행할 수 없는 상태
        * CPU나 컴파일러는 이에 대한 적절한 처리를 수행해야 한다.
        * 종류
          * 구조 해저드 : 하드웨어의 구조적 한계로 인한 해저드 (메모리 읽기와 쓰기가 동시에 일어날 수 없는 경우)
          * 데이터 해저드 : 데이터 의존성으로 인한 해저드 (먼저 실행된 명령의 연산 결과를 뒤의 명령이 사용해야 할 때) 
          * 제어 해저드 : 조건 분기가 있을 때 발생 (명령1이 분기고 그 결과에 따라 명령2이 수행되는 경우)

## 동시 처리와 병렬 처리의 필요성성
* 병렬 처리와 성능 향상
  * 병렬 처리는 단순히 성능 향상을 위해 필요하다.
  * 데이터 병렬성, 인스트럭션 병렬성은 컴파일러나 하드웨어가 암묵적으로 수행함.
  * 태스크 병렬성은 멀티코어 CPU 등장으로 소프트웨어 관점에서 의식해야 하는 문제가 되었다.
  * 그럼 왜 멀티코어가 만들어졌는가?
    * 이 질문에 답을 하기 위해서는 왜 반도체의 성능을 무한히 높힐 수 없는지를 알아봐야 함.
      * 반도체 단위 면적당 성능을 높이기 위해 회로 집적도를 높혔다.
      * 이를 통해 트랜지스터를 빠르게 On,Off 할 수 있게 되어 작동 클록도 높힐 수 있는 이점이 있다.
      * 반면에 발열이 커져 회로가 불안정해지는 문제가 발생한다. 그래서 주파수를 유지한 채로 인가 전압을 낮추는 방향으로 발전
      * 일정 이상 반도체 소자가 미세화되자 트랜지스터 안에서의 전류 누출이 문제가 되었다. (양자 터널 효과)
      * 전류 누출은 전력이 쓸데없이 소비되고 발열 및 오작동의 원인이 된다.
    * 그러므로 이에 대한 대안으로 코어 수를 늘려 성능 향상을 노렸다고 볼 수 있다. 
* 동시 처리의 필요성과 계산 경로 수 급증
  * 동시 처리가 중요한 이유
    * 효율적인 계산 리소스 활용
    * 공평성 (공정성) : 여러 프로세스가 공평하게 처리 기회를 얻는 것은 중요하다.
    * 편리성
  * 계산 경로의 급증
    * 동시에 계산해야 하는 작업이 많아질 수록 계산 경로도 급증하게 된다. 
    * 동시에 n개의 프로세스가 동작하는 경우 : $n!$



